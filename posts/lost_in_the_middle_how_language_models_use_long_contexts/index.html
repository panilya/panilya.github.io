<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Illia Pantsyr"><meta name=description content="Almost 1 year ago, Lost in the Middle: How Language Models Use Long Contexts paper was published that empirically investigated the effectiveness of finding information in the input context depending on the location of the correct answer in the context among other relevant information. The researchers used gpt-3.5-turbo, gpt-3.5-turbo-16k, Claude 1.3, Claude 1.3 (100k), MPT-30B-Instruct and LongChat-13B (16k) and found that the quality jumps A LOT when you change the position of a piece of text with the correct answer among other relevant text that does not contain the answer to the question."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Paper summary | Lost in the Middle: How Language Models Use Long Contexts"><meta name=twitter:description content="Almost 1 year ago, Lost in the Middle: How Language Models Use Long Contexts paper was published that empirically investigated the effectiveness of finding information in the input context depending on the location of the correct answer in the context among other relevant information. The researchers used gpt-3.5-turbo, gpt-3.5-turbo-16k, Claude 1.3, Claude 1.3 (100k), MPT-30B-Instruct and LongChat-13B (16k) and found that the quality jumps A LOT when you change the position of a piece of text with the correct answer among other relevant text that does not contain the answer to the question."><meta property="og:title" content="Paper summary | Lost in the Middle: How Language Models Use Long Contexts"><meta property="og:description" content="Almost 1 year ago, Lost in the Middle: How Language Models Use Long Contexts paper was published that empirically investigated the effectiveness of finding information in the input context depending on the location of the correct answer in the context among other relevant information. The researchers used gpt-3.5-turbo, gpt-3.5-turbo-16k, Claude 1.3, Claude 1.3 (100k), MPT-30B-Instruct and LongChat-13B (16k) and found that the quality jumps A LOT when you change the position of a piece of text with the correct answer among other relevant text that does not contain the answer to the question."><meta property="og:type" content="article"><meta property="og:url" content="https://panilya.github.io/posts/lost_in_the_middle_how_language_models_use_long_contexts/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-07-03T00:00:00+00:00"><meta property="article:modified_time" content="2024-07-03T00:00:00+00:00"><title>Illia Pantsyr</title><link rel=canonical href=https://panilya.github.io/posts/lost_in_the_middle_how_language_models_use_long_contexts/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.6b1a4fbc48955b72aea7913e43fabeb45e8bc120da5aa41b598dd33adcac4b59.css integrity="sha256-axpPvEiVW3Kup5E+Q/q+tF6LwSDaWqQbWY3TOtysS1k=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css integrity="sha256-OeQafxa9+MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/img/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/img/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.119.0"></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>Illia Pantsyr</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/about/>About</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://panilya.github.io/posts/lost_in_the_middle_how_language_models_use_long_contexts/>Paper summary | Lost in the Middle: How Language Models Use Long Contexts</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2024-07-03T00:00:00Z>July 3, 2024</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
3-minute read</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/llm/>llm</a></span>
<span class=separator>•</span>
<span class=tag><a href=/tags/ai/>ai</a></span></div></div></header><div><p>Almost 1 year ago, <a href=https://arxiv.org/abs/2307.03172>Lost in the Middle: How Language Models Use Long Contexts</a> paper was published that empirically investigated the effectiveness of finding information in the input context depending on the location of the correct answer in the context among other relevant information. The researchers used <code>gpt-3.5-turbo</code>, <code>gpt-3.5-turbo-16k</code>, <code>Claude 1.3</code>, <code>Claude 1.3 (100k)</code>, <code>MPT-30B-Instruct</code> and <code>LongChat-13B (16k)</code> and found that the quality jumps A LOT when you change the position of a piece of text with the correct answer among other relevant text that does not contain the answer to the question.</p><p>To measure how much the answer performance varies, the authors took 20 pieces of Wikipedia pages, only one of which contained the exact answer to the question (the rest were quite relevant but did not contain the answer to the question) and started moving the paragraph with the answer to the beginning, then further, and so on, trying all positions. As it turned out, the proportion of correct answers when placing the paragraph with the answer in the middle of the input context fell below 55%, which is the level of generating a correct answer to a question using model’s parameter memory (without passing information in a prompt). If you place the answer paragraph at the very beginning, the share of correct answers to the same question will be 75%, where the paragraph with the correct answer at the very end will be around 65%.</p><p><img src=/lost_in_the_middle_how_language_models_use_long_contexts/multi_document_relevant_info_performance.png alt=multi_document_relevant_info_performance.png></p><p>Performing a smaller experiment (because &ldquo;Evaluating GPT-4 on the full multi-document QA and key-value retrieval experiments would cost upwards of $6000&rdquo;) using the <code>gpt-4-0613</code> model with 20 documents in the input context, it performed significantly better than any other model, although you can still see a U-shaped curve, indicating that even for newer models, the location of the answer information affects the result.</p><p><img src=/lost_in_the_middle_how_language_models_use_long_contexts/multi_document_gpt_4_performance.png alt=multi_document_gpt_4_performance.png></p><p>Additionally, the authors thought: &ldquo;maybe the model is just confusing the information we are feeding it&rdquo;? and so they decided to try to measure performance on a synthetic task. To do this, they generated 75, 140, and 300 key-value pairs where keys and values are unique, randomly-generated UUIDs, and asked the model to return the value by key. Although some models showed perfect results on this task, you can still see that the answer at the beginning or at the end gives better results.</p><p><img src=/lost_in_the_middle_how_language_models_use_long_contexts/synthetic_task_relevant_info_performance.png alt=synthetic_task_relevant_info_performance.png></p><p>Although almost a year has passed since the paper was written and the models have improved significantly, it is useful to know about this behavior of LLM models with a large context window.</p><p>If you find this paper summary interesting - go ahead and read the paper in full: <a href=https://arxiv.org/pdf/2307.03172>Lost in the Middle: How Language Models Use Long Contexts</a></p></div><footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//Illia Pantsyr.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></footer></article></section></div><footer class=footer><section class=container>©
2022 -
2024
Illia Pantsyr
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js integrity="sha256-I2BJOV3DaC+ycZZAhylY4S8fJAZ7sJwyeyM+YpDH7aw="></script>
<script data-goatcounter=https://panilya.goatcounter.com/count async src=//gc.zgo.at/count.js></script></body></html>