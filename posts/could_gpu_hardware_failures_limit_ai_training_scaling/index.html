<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Illia Pantsyr"><meta name=description content="A fresh analytical report from Epoch AI on the continued scaling of training capacity. In this work, they attempt to answer the following question: to what extent is scaling limited by hardware issues?
Graphics processing units (GPUs) can fail during training for various reasons: memory damage, disconnections/restarts, or network issues. Even a single slightly slowed-down GPU can become a bottleneck for the entire system if not replaced promptly.
When Meta trained its largest model, Llama 3."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Could GPU hardware failures limit AI training scaling?"><meta name=twitter:description content="A fresh analytical report from Epoch AI on the continued scaling of training capacity. In this work, they attempt to answer the following question: to what extent is scaling limited by hardware issues?
Graphics processing units (GPUs) can fail during training for various reasons: memory damage, disconnections/restarts, or network issues. Even a single slightly slowed-down GPU can become a bottleneck for the entire system if not replaced promptly.
When Meta trained its largest model, Llama 3."><meta property="og:title" content="Could GPU hardware failures limit AI training scaling?"><meta property="og:description" content="A fresh analytical report from Epoch AI on the continued scaling of training capacity. In this work, they attempt to answer the following question: to what extent is scaling limited by hardware issues?
Graphics processing units (GPUs) can fail during training for various reasons: memory damage, disconnections/restarts, or network issues. Even a single slightly slowed-down GPU can become a bottleneck for the entire system if not replaced promptly.
When Meta trained its largest model, Llama 3."><meta property="og:type" content="article"><meta property="og:url" content="https://panilya.github.io/posts/could_gpu_hardware_failures_limit_ai_training_scaling/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-11-23T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-23T00:00:00+00:00"><title>Illia Pantsyr</title><link rel=canonical href=https://panilya.github.io/posts/could_gpu_hardware_failures_limit_ai_training_scaling/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.6b1a4fbc48955b72aea7913e43fabeb45e8bc120da5aa41b598dd33adcac4b59.css integrity="sha256-axpPvEiVW3Kup5E+Q/q+tF6LwSDaWqQbWY3TOtysS1k=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css integrity="sha256-OeQafxa9+MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/img/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/img/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.119.0"></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>Illia Pantsyr</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/about/>About</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://panilya.github.io/posts/could_gpu_hardware_failures_limit_ai_training_scaling/>Could GPU hardware failures limit AI training scaling?</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2024-11-23T00:00:00Z>November 23, 2024</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
3-minute read</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/llm/>llm</a></span>
<span class=separator>•</span>
<span class=tag><a href=/tags/ai/>ai</a></span></div></div></header><div><p>A fresh analytical <a href=https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling>report</a> from Epoch AI on the continued scaling of training capacity. In this work, they attempt to answer the following question: to what extent is scaling limited by hardware issues?</p><p>Graphics processing units (GPUs) can fail during training for various reasons: memory damage, disconnections/restarts, or network issues. Even a single slightly slowed-down GPU can become a bottleneck for the entire system if not replaced promptly.</p><p>When Meta trained its largest model, Llama 3.1 with 405B parameters, on 16,000 GPUs, there were over 400 hardware failures over 54 days—roughly one every three hours. If this is scaled up to setups with over a million GPUs, failures would occur every few minutes.</p><p>A failure almost always results in the loss of data in memory, disrupting training. To mitigate this, models are regularly saved during training (this process is called “checkpointing”) to preserve the training state (including the model itself and optimizer statistics). This allows recovery from a recent point in training immediately after a failure, enabling the process to continue.</p><p>However, saving checkpoints takes time, and training cannot proceed if the time spent saving, loading, and synchronizing exceeds the interval between hardware failures. For instance, during the training of the Llama 3.1 405B model, progress was saved to storage with a throughput of 2 TB/s. Saving the necessary ~5 TB of information took about 2.5 seconds.</p><p>If we fix the model size, maintain storage bandwidth, and keep the hardware failure frequency constant, training could theoretically scale up to ~70 million GPUs. However, on such a massive cluster, it’s likely that even larger models would be trained (this is more efficient in terms of final quality), and as model size grows, so does the amount of data that needs to be saved.</p><p>The authors estimate that with the current commonly accepted pace of scaling, clusters could grow to ~4 million GPUs, which is still more than what’s planned before 2030 (rumors suggest a target of 1M chips). And this is without leveraging advanced saving techniques (e.g., reserving part of the memory on all GPUs and splitting the model among them. Such a subnet within the GPUs themselves is faster than external storage. More details on this in the article).</p><p>Thus, these kinds of issues (for now) do not limit scaling. Overcoming hardware failures will remain a serious engineering challenge, requiring efficient on-the-fly GPU replacements, maintenance, and safeguards against unforeseen events. But this impacts only the speed of training, not its feasibility.</p><h3 id=citing--source>Citing / Source
<a class=heading-link href=#citing--source><i class="fa fa-link" aria-hidden=true></i></a></h3><p>Alexander Erben and Ege Erdil (2024), &ldquo;Hardware Failures Won’t Limit AI Scaling&rdquo;. Published online at epoch.ai. Retrieved from: &lsquo;<a href="https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling'">https://epoch.ai/blog/hardware-failures-wont-limit-ai-scaling'</a> [online resource]</p></div><footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//Illia Pantsyr.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></footer></article></section></div><footer class=footer><section class=container>©
2022 -
2024
Illia Pantsyr
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js integrity="sha256-I2BJOV3DaC+ycZZAhylY4S8fJAZ7sJwyeyM+YpDH7aw="></script>
<script data-goatcounter=https://panilya.goatcounter.com/count async src=//gc.zgo.at/count.js></script></body></html>