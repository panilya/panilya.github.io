<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>llm on Illia Pantsyr</title><link>https://panilya.github.io/tags/llm/</link><description>Recent content in llm on Illia Pantsyr</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 04 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://panilya.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml"/><item><title>Domain-Specific Large Language Models as the Next Milestone</title><link>https://panilya.github.io/posts/domain_specific_large_language_models_as_the_next_milestone/</link><pubDate>Sun, 04 May 2025 00:00:00 +0000</pubDate><guid>https://panilya.github.io/posts/domain_specific_large_language_models_as_the_next_milestone/</guid><description>The rapid evolution of Generative AI, particularly Large Language Models (LLMs), has reshaped many aspects of technology and industry. As general-purpose models like GPT-4o, Claude, and Gemini demonstrate increasingly sophisticated capabilities, the question arises: what is the next major milestone in this field? While advancements continue on multiple fronts, a compelling case can be made for Domain-Specific Large Language Models (DLLMs) representing the next significant leap forward. This post explores why specializing LLMs for particular fields might be the crucial next step in unlocking their full potential.</description></item><item><title>Anthropic demonstrated how AI can analyze itself</title><link>https://panilya.github.io/posts/anthropic_demonstrated_how_ai_can_analyze_itself/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://panilya.github.io/posts/anthropic_demonstrated_how_ai_can_analyze_itself/</guid><description>Yesterday, Anthropic published an amazing studyâ€”they developed a system called Clio, which can safely analyze millions of conversations with the AI assistant Claude.
A New Perspective on AI Usage Clio allows for examining real-life scenarios of AI usage in everyday life while preserving user privacy by working only with aggregated data. Anthropic has revealed fascinating trends:
Most popular tasks: Users primarily rely on AI for programming, content creation, and research. Cultural differences: AI usage varies by region; for instance, in Japan, discussions often center on societal challenges like aging populations.</description></item><item><title>Could GPU hardware failures limit AI training scaling?</title><link>https://panilya.github.io/posts/could_gpu_hardware_failures_limit_ai_training_scaling/</link><pubDate>Sat, 23 Nov 2024 00:00:00 +0000</pubDate><guid>https://panilya.github.io/posts/could_gpu_hardware_failures_limit_ai_training_scaling/</guid><description>A fresh analytical report from Epoch AI on the continued scaling of training capacity. In this work, they attempt to answer the following question: to what extent is scaling limited by hardware issues?
Graphics processing units (GPUs) can fail during training for various reasons: memory damage, disconnections/restarts, or network issues. Even a single slightly slowed-down GPU can become a bottleneck for the entire system if not replaced promptly.
When Meta trained its largest model, Llama 3.</description></item><item><title>Paper summary | Lost in the Middle: How Language Models Use Long Contexts</title><link>https://panilya.github.io/posts/lost_in_the_middle_how_language_models_use_long_contexts/</link><pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate><guid>https://panilya.github.io/posts/lost_in_the_middle_how_language_models_use_long_contexts/</guid><description>Almost 1 year ago, Lost in the Middle: How Language Models Use Long Contexts paper was published that empirically investigated the effectiveness of finding information in the input context depending on the location of the correct answer in the context among other relevant information. The researchers used gpt-3.5-turbo, gpt-3.5-turbo-16k, Claude 1.3, Claude 1.3 (100k), MPT-30B-Instruct and LongChat-13B (16k) and found that the quality jumps A LOT when you change the position of a piece of text with the correct answer among other relevant text that does not contain the answer to the question.</description></item></channel></rss>